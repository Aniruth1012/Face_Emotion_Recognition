{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mkxnj24OCAab"
   },
   "source": [
    "Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K1558Kz8B_a5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znNOgk7CCJhE"
   },
   "source": [
    "Preprocessing the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VLlJjRptCL_I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12102 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "training_set=train_datagen.flow_from_directory(r\"D:\\face sentiment analysis dataset\\images\\images\\train\",batch_size=32,class_mode='binary',target_size=(64,64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZsP1JuPFJy4"
   },
   "source": [
    "Preprocessing the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AVd8u3ZiFMFj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2964 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "test_set=test_datagen.flow_from_directory(r\"D:\\face sentiment analysis dataset\\images\\images\\validation\",batch_size=32,target_size=(64,64),class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8wFbYxZFoJk"
   },
   "source": [
    "Initializing the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GhBNEH3qFrEd"
   },
   "outputs": [],
   "source": [
    "cnn=tf.keras.models.Sequential()\n",
    "cnn.add(tf.keras.layers.Conv2D(kernel_size=3,filters=32,activation='relu',input_shape=[64,64,3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
    "cnn.add(tf.keras.layers.Conv2D(kernel_size=3,filters=32,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dense(units=128,activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aX-T-fflG3a7"
   },
   "source": [
    "Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3OZSRXwHG5Vg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "379/379 [==============================] - 55s 142ms/step - loss: 0.6267 - accuracy: 0.6496 - val_loss: 0.5317 - val_accuracy: 0.7287\n",
      "Epoch 2/60\n",
      "379/379 [==============================] - 44s 117ms/step - loss: 0.5463 - accuracy: 0.7155 - val_loss: 0.4874 - val_accuracy: 0.7594\n",
      "Epoch 3/60\n",
      "379/379 [==============================] - 43s 114ms/step - loss: 0.5025 - accuracy: 0.7437 - val_loss: 0.4419 - val_accuracy: 0.7817\n",
      "Epoch 4/60\n",
      "379/379 [==============================] - 41s 107ms/step - loss: 0.4692 - accuracy: 0.7684 - val_loss: 0.4333 - val_accuracy: 0.7841\n",
      "Epoch 5/60\n",
      "379/379 [==============================] - 41s 108ms/step - loss: 0.4414 - accuracy: 0.7839 - val_loss: 0.4207 - val_accuracy: 0.7949\n",
      "Epoch 6/60\n",
      "379/379 [==============================] - 41s 108ms/step - loss: 0.4223 - accuracy: 0.7935 - val_loss: 0.4008 - val_accuracy: 0.8195\n",
      "Epoch 7/60\n",
      "379/379 [==============================] - 41s 107ms/step - loss: 0.4024 - accuracy: 0.8059 - val_loss: 0.4116 - val_accuracy: 0.8016\n",
      "Epoch 8/60\n",
      "379/379 [==============================] - 40s 106ms/step - loss: 0.3945 - accuracy: 0.8148 - val_loss: 0.3701 - val_accuracy: 0.8286\n",
      "Epoch 9/60\n",
      "379/379 [==============================] - 41s 107ms/step - loss: 0.3697 - accuracy: 0.8260 - val_loss: 0.3723 - val_accuracy: 0.8289\n",
      "Epoch 10/60\n",
      "379/379 [==============================] - 41s 107ms/step - loss: 0.3602 - accuracy: 0.8285 - val_loss: 0.3621 - val_accuracy: 0.8387\n",
      "Epoch 11/60\n",
      "379/379 [==============================] - 38s 101ms/step - loss: 0.3445 - accuracy: 0.8412 - val_loss: 0.3637 - val_accuracy: 0.8320\n",
      "Epoch 12/60\n",
      "379/379 [==============================] - 38s 101ms/step - loss: 0.3309 - accuracy: 0.8479 - val_loss: 0.3493 - val_accuracy: 0.8418\n",
      "Epoch 13/60\n",
      "379/379 [==============================] - 38s 101ms/step - loss: 0.3222 - accuracy: 0.8523 - val_loss: 0.4127 - val_accuracy: 0.8313\n",
      "Epoch 14/60\n",
      "379/379 [==============================] - 37s 99ms/step - loss: 0.3156 - accuracy: 0.8586 - val_loss: 0.3441 - val_accuracy: 0.8499\n",
      "Epoch 15/60\n",
      "379/379 [==============================] - 38s 100ms/step - loss: 0.3021 - accuracy: 0.8651 - val_loss: 0.3511 - val_accuracy: 0.8435\n",
      "Epoch 16/60\n",
      "379/379 [==============================] - 40s 106ms/step - loss: 0.2937 - accuracy: 0.8675 - val_loss: 0.3328 - val_accuracy: 0.8519\n",
      "Epoch 17/60\n",
      "379/379 [==============================] - 39s 104ms/step - loss: 0.2804 - accuracy: 0.8776 - val_loss: 0.3431 - val_accuracy: 0.8495\n",
      "Epoch 18/60\n",
      "379/379 [==============================] - 40s 107ms/step - loss: 0.2704 - accuracy: 0.8812 - val_loss: 0.3357 - val_accuracy: 0.8620\n",
      "Epoch 19/60\n",
      "379/379 [==============================] - 40s 105ms/step - loss: 0.2682 - accuracy: 0.8833 - val_loss: 0.3328 - val_accuracy: 0.8553\n",
      "Epoch 20/60\n",
      "379/379 [==============================] - 41s 107ms/step - loss: 0.2484 - accuracy: 0.8936 - val_loss: 0.3318 - val_accuracy: 0.8586\n",
      "Epoch 21/60\n",
      "379/379 [==============================] - 40s 106ms/step - loss: 0.2452 - accuracy: 0.8941 - val_loss: 0.3278 - val_accuracy: 0.8566\n",
      "Epoch 22/60\n",
      "379/379 [==============================] - 40s 106ms/step - loss: 0.2446 - accuracy: 0.8934 - val_loss: 0.3229 - val_accuracy: 0.8607\n",
      "Epoch 23/60\n",
      "379/379 [==============================] - 39s 104ms/step - loss: 0.2348 - accuracy: 0.9006 - val_loss: 0.3272 - val_accuracy: 0.8617\n",
      "Epoch 24/60\n",
      "379/379 [==============================] - 40s 105ms/step - loss: 0.2192 - accuracy: 0.9063 - val_loss: 0.3359 - val_accuracy: 0.8570\n",
      "Epoch 25/60\n",
      "379/379 [==============================] - 40s 105ms/step - loss: 0.2189 - accuracy: 0.9077 - val_loss: 0.3489 - val_accuracy: 0.8603\n",
      "Epoch 26/60\n",
      "379/379 [==============================] - 40s 105ms/step - loss: 0.2062 - accuracy: 0.9170 - val_loss: 0.3451 - val_accuracy: 0.8637\n",
      "Epoch 27/60\n",
      "379/379 [==============================] - 40s 105ms/step - loss: 0.2115 - accuracy: 0.9103 - val_loss: 0.3373 - val_accuracy: 0.8644\n",
      "Epoch 28/60\n",
      "379/379 [==============================] - 40s 106ms/step - loss: 0.2016 - accuracy: 0.9189 - val_loss: 0.3672 - val_accuracy: 0.8634\n",
      "Epoch 29/60\n",
      "379/379 [==============================] - 39s 103ms/step - loss: 0.1953 - accuracy: 0.9195 - val_loss: 0.3577 - val_accuracy: 0.8640\n",
      "Epoch 30/60\n",
      "379/379 [==============================] - 40s 105ms/step - loss: 0.1913 - accuracy: 0.9239 - val_loss: 0.3508 - val_accuracy: 0.8620\n",
      "Epoch 31/60\n",
      "379/379 [==============================] - 40s 105ms/step - loss: 0.1826 - accuracy: 0.9243 - val_loss: 0.3767 - val_accuracy: 0.8563\n",
      "Epoch 32/60\n",
      "379/379 [==============================] - 40s 104ms/step - loss: 0.1735 - accuracy: 0.9292 - val_loss: 0.3732 - val_accuracy: 0.8637\n",
      "Epoch 33/60\n",
      "379/379 [==============================] - 40s 105ms/step - loss: 0.1777 - accuracy: 0.9298 - val_loss: 0.3673 - val_accuracy: 0.8691\n",
      "Epoch 34/60\n",
      "379/379 [==============================] - 44s 116ms/step - loss: 0.1661 - accuracy: 0.9323 - val_loss: 0.3806 - val_accuracy: 0.8671\n",
      "Epoch 35/60\n",
      "379/379 [==============================] - 48s 126ms/step - loss: 0.1553 - accuracy: 0.9370 - val_loss: 0.3852 - val_accuracy: 0.8603\n",
      "Epoch 36/60\n",
      "379/379 [==============================] - 54s 142ms/step - loss: 0.1532 - accuracy: 0.9417 - val_loss: 0.4114 - val_accuracy: 0.8623\n",
      "Epoch 37/60\n",
      "379/379 [==============================] - 50s 132ms/step - loss: 0.1524 - accuracy: 0.9393 - val_loss: 0.3892 - val_accuracy: 0.8694\n",
      "Epoch 38/60\n",
      "379/379 [==============================] - 39s 102ms/step - loss: 0.1483 - accuracy: 0.9427 - val_loss: 0.3813 - val_accuracy: 0.8721\n",
      "Epoch 39/60\n",
      "379/379 [==============================] - 41s 108ms/step - loss: 0.1453 - accuracy: 0.9448 - val_loss: 0.3955 - val_accuracy: 0.8677\n",
      "Epoch 40/60\n",
      "379/379 [==============================] - 40s 105ms/step - loss: 0.1376 - accuracy: 0.9473 - val_loss: 0.4035 - val_accuracy: 0.8603\n",
      "Epoch 41/60\n",
      "379/379 [==============================] - 41s 109ms/step - loss: 0.1453 - accuracy: 0.9422 - val_loss: 0.4140 - val_accuracy: 0.8688\n",
      "Epoch 42/60\n",
      "379/379 [==============================] - 42s 110ms/step - loss: 0.1370 - accuracy: 0.9463 - val_loss: 0.4044 - val_accuracy: 0.8708\n",
      "Epoch 43/60\n",
      "379/379 [==============================] - 45s 119ms/step - loss: 0.1333 - accuracy: 0.9508 - val_loss: 0.4361 - val_accuracy: 0.8711\n",
      "Epoch 44/60\n",
      "379/379 [==============================] - 44s 116ms/step - loss: 0.1264 - accuracy: 0.9512 - val_loss: 0.4186 - val_accuracy: 0.8634\n",
      "Epoch 45/60\n",
      "379/379 [==============================] - 38s 99ms/step - loss: 0.1225 - accuracy: 0.9528 - val_loss: 0.4157 - val_accuracy: 0.8694\n",
      "Epoch 46/60\n",
      "379/379 [==============================] - 39s 102ms/step - loss: 0.1263 - accuracy: 0.9505 - val_loss: 0.4125 - val_accuracy: 0.8742\n",
      "Epoch 47/60\n",
      "379/379 [==============================] - 43s 113ms/step - loss: 0.1166 - accuracy: 0.9555 - val_loss: 0.4036 - val_accuracy: 0.8688\n",
      "Epoch 48/60\n",
      "379/379 [==============================] - 42s 112ms/step - loss: 0.1118 - accuracy: 0.9580 - val_loss: 0.4470 - val_accuracy: 0.8637\n",
      "Epoch 49/60\n",
      "379/379 [==============================] - 38s 101ms/step - loss: 0.1148 - accuracy: 0.9554 - val_loss: 0.4203 - val_accuracy: 0.8681\n",
      "Epoch 50/60\n",
      "379/379 [==============================] - 39s 103ms/step - loss: 0.1126 - accuracy: 0.9582 - val_loss: 0.4356 - val_accuracy: 0.8654\n",
      "Epoch 51/60\n",
      "379/379 [==============================] - 41s 109ms/step - loss: 0.1048 - accuracy: 0.9611 - val_loss: 0.4420 - val_accuracy: 0.8728\n",
      "Epoch 52/60\n",
      "379/379 [==============================] - 43s 114ms/step - loss: 0.1102 - accuracy: 0.9588 - val_loss: 0.4740 - val_accuracy: 0.8661\n",
      "Epoch 53/60\n",
      "379/379 [==============================] - 42s 110ms/step - loss: 0.1108 - accuracy: 0.9576 - val_loss: 0.4346 - val_accuracy: 0.8738\n",
      "Epoch 54/60\n",
      "379/379 [==============================] - 39s 103ms/step - loss: 0.1025 - accuracy: 0.9619 - val_loss: 0.4528 - val_accuracy: 0.8674\n",
      "Epoch 55/60\n",
      "379/379 [==============================] - 38s 99ms/step - loss: 0.1058 - accuracy: 0.9612 - val_loss: 0.4726 - val_accuracy: 0.8620\n",
      "Epoch 56/60\n",
      "379/379 [==============================] - 35s 93ms/step - loss: 0.0962 - accuracy: 0.9641 - val_loss: 0.4627 - val_accuracy: 0.8765\n",
      "Epoch 57/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 33s 86ms/step - loss: 0.0912 - accuracy: 0.9670 - val_loss: 0.4665 - val_accuracy: 0.8691\n",
      "Epoch 58/60\n",
      "379/379 [==============================] - 32s 85ms/step - loss: 0.0939 - accuracy: 0.9654 - val_loss: 0.4767 - val_accuracy: 0.8721\n",
      "Epoch 59/60\n",
      "379/379 [==============================] - 43s 112ms/step - loss: 0.0947 - accuracy: 0.9620 - val_loss: 0.4556 - val_accuracy: 0.8758\n",
      "Epoch 60/60\n",
      "379/379 [==============================] - 38s 99ms/step - loss: 0.0903 - accuracy: 0.9668 - val_loss: 0.4796 - val_accuracy: 0.8806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20b498d3b50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "cnn.fit(x=training_set,validation_data=test_set,epochs=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I52EmsrLHTKw"
   },
   "source": [
    "Make a Single Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yyPmx1JWH6mh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "happy\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "test_image=image.load_img(r\"D:\\face sentiment sample\\tj_test1.png\",target_size=(64,64))\n",
    "test_image=image.img_to_array(test_image)\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "result=cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0]==1:\n",
    "  prediction='sad'\n",
    "else:\n",
    "  prediction='happy'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(cnn,open('model1.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step\n",
      "happy\n"
     ]
    }
   ],
   "source": [
    "model=pickle.load(open('model1.pkl','rb'))\n",
    "results=model.predict(test_image)\n",
    "if results[0][0]==1:\n",
    "    print('sad')\n",
    "else:\n",
    "    print('happy')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
